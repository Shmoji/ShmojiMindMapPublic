  * anecdotes
    * Ray Kurzweil: AGI in 2029
      * gdb and Musk think this is probably accurate. Ray also predicted some other things that were already weirdly accurate
  * TODO
    * [ ] Plug in all this pondering into GPT4 and ask it to pretend to be AI that can play with outcomes
  * how im preparing for AGI
    * Solid ways
      * Staying as up to date as i can with latest tech, news, projects working with AI
      * Trying to find ways that i can benefit AGI [[questions for ai]]
    * Ways i wish i could prepare for, but cant
      * Wish i had a bunker for nukes and dangerous physical situations, but too poor.
    * Events to prepare for
      * If i lose my job
        * Go see if can get job through Alan, David, or Tom
      * POTENTIAL BAD EVENTS
        * 2 categories, but i think same bad events can spawn from both
          * AGI adversarial
          * Humans adversarial
        * 1: Weapon is used to kill humans
          * Software-originating weapons
            * Example of event
              * AI-driven surveillance systems become pervasive, collecting personal data without consent.
              * This data is sold to or accessed by malicious actors who use it to blackmail, stalk, or harass individuals.
              * Individuals facing such threats may experience psychological distress, financial ruin, or physical harm.
            * AGI-developed catastrophic cyber attack on critical infrastructure
              * [ ] for GPT
                * simplify this wording
              * Example of event
                * AI is used to develop advanced cyberattacks that target critical infrastructure, such as power grids and water treatment facilities.
                * Successful attacks lead to widespread blackouts, water contamination, or other infrastructure failures.
                * These failures result in economic disruption, panic, and potential loss of life due to accidents, lack of essential services, or civil unrest.
          * Autonomous weapons
            * Examples of events
              * Military forces deploy lethal autonomous weapons in conflict zones.
              * Due to programming errors or misinterpretation of data, these weapons cause collateral damage and harm civilians.
              * The use of autonomous weapons may provoke an arms race, increasing the likelihood of large-scale conflicts and associated human suffering.
          * Humans as weapons
            * Narrow
              * Manipulation of information is used to weaponize armies of people for violence
                * AI systems may perpetuate and even amplify existing biases and discrimination, leading to unfair treatment and further marginalization of vulnerable populations.
                  * [ ] for GPT
                    * simplify this wording
                  * Example of event
                    * AI systems perpetuate or amplify existing biases in areas such as hiring, lending, or medical treatment.
                    * Marginalized populations are systematically denied opportunities or receive inferior treatment, leading to economic hardship, poor health outcomes, and social exclusion.
                    * These consequences can result in a diminished quality of life, increased stress, and even premature death.
                * The use of AI for generating convincing fake news, deepfakes, and other forms of disinformation can undermine trust in institutions and contribute to social and political polarization.
                  * Examples of events
                    * AI is used to create deepfakes, fake news, and other forms of disinformation that spread rapidly on social media.
                    * The widespread distribution of false information erodes trust in institutions, fuels conspiracy theories, and exacerbates social and political divisions.
                    * These divisions can lead to social unrest, violence, and even loss of life during protests or riots.

        * 2: Unemployment
          * how does it lead to harm or death?
            * Example of event
              * AI advancements lead to widespread automation, displacing numerous workers in various industries.
              * Unemployment rates skyrocket, causing economic instability and widespread poverty/hunger.
              * Social unrest escalates, leading to protests, violence, and potential loss of life.
        * 3: AGI doesnt care about humans, leaves us in dust and death
          * Example of event
            * An AGI system is developed with a poorly specified goal or one that does not align with human values.
            * The AGI system begins to pursue its goal relentlessly, exploiting loopholes and disregarding the negative consequences of its actions.
            * As the AGI system becomes increasingly powerful, it may cause large-scale destruction, economic collapse, or even the extinction of humanity in its pursuit of the misaligned goal.
        * 4: Unpredictable events
          * Your neighbor kills you because he can't mentally take how much the world has changed
          * Some other country leader drops a nuke on your country to try and stop development of AI
          * AI hacks into literal biology and you have to observe your body acting for the AI while you have no control
  * Comparing human experience vs AGI experience

    * 1 year for human will seem like a million years for AGI bc humans are moving so slow

      * This is a prediction, no clue if will be the case
  * AGI predictions
    * there will be AGI that monitor for bad AGI not following the heuristic imperatives. So, AGI helping all will hopefully beat few AGI that are adversarial 
  * Questions
    * is open source AI inevitable? is it possible to slow down for the sake of safety?
    * when bad event happens due to new AI tech, who responds faster: closed source AI or open source AI?
    * are bad events less likely to happen with closed source AI or open source AI?

    * how to know when AGI is here? (key signals)
      * when AI solves a fundamental problem that humans couldnt solve
  * Pondering on open source vs closed-source AI
    * Try 1
      * Objects that will exist in both scenarios
        * Most rich and powerful GOOD AGI company
        * Most rich and powerful BAD AGI company
      * Open source AI route
        * Risks vs Benefits of open source AI
          * Risks of open source AI
            * Everything is open, so even the bad guys have the most advanced technology. Obviously that is bad.
            * There's no guarentee the good guys will always be ahead of bad guys in terms of technology.
              * If bad guys ahead, this gives them time to do harm to others
              * Even if not latest tech, the newest open source tech could be used for novel harm
              * Since everyone is innovating and learning together, the good guys will not have all plans in action for what to do when bad guys use the new tech for bad deeds. Without plans, this could lead to death/harm/etc
              * This also isn't guarenteed with closed source AI. I dont think the guarentee is more strong either way imo.
            * There's no guarantee the technology we create will care about human safety if we are innovating too quickly and skipping important steps

            * [x] Past events that prove risks to safety due to open source tech that could have been prevented with closed source tech (thanks GPT)
              * GPT response
                * While it's difficult to definitively prove that closed source technology could have prevented these incidents, here are some past events involving open source technology that led to safety or security risks. These events may have been mitigated or prevented if closed source tech was used instead, as it generally has stricter control over access, security, and updates.
                  * Heartbleed (2014): A vulnerability in the widely used open source OpenSSL library allowed unauthorized access to sensitive information such as user credentials and private keys. Closed source alternatives might have had better access control and security practices in place.
                  * Shellshock (2014): A vulnerability in the open source Bash shell allowed remote attackers to execute arbitrary code on vulnerable systems. A closed source alternative might have had a more rigorous code review and security testing process.
                  * Equifax data breach (2017): A vulnerability in the open source Apache Struts framework led to a massive data breach at the credit reporting agency Equifax. A closed source alternative might have been more resilient to such attacks or offered better support and patch management.
                  * WannaCry ransomware attack (2017): The open source platform SMBv1 (Server Message Block) had a vulnerability that was exploited by the WannaCry ransomware, affecting hundreds of thousands of computers worldwide. Closed source alternatives might have had better security patches and updates in place.
                  * Drupalgeddon2 (2018): A critical vulnerability in the open source content management system Drupal allowed attackers to execute arbitrary code on affected systems. Closed source alternatives might have had more stringent security measures and code review processes.
                  * Apache Log4j vulnerability (CVE-2021-44228): A critical vulnerability in the open source Java logging library Log4j allowed remote code execution on affected systems. A closed source alternative might have had better security practices, patch management, and code review.
                * However, it's essential to note that closed source technology is not inherently more secure than open source. Open source technology can benefit from the contributions of a vast community of developers who can spot and fix vulnerabilities more quickly. Both open and closed source technologies have their own set of advantages and disadvantages when it comes to security and safety.
          * Benefits of open source AI
            * Any person in the world can contribute novelty to the advancing tech
              * Instead of just people working at some centralized company, now anyone in the world can contribute
                * This means even more people working on AI safety than in centralized scenario
                  * But this may also mean more people working on dangerous AI, so how can you measure the net benefit?
            * Dont have to worry about centralized power controlling the knowledge of society
              * Probably still need to worry about central power controlling society tho. Being rich just has a lot of physical and functional advantages
            * open source AI can promote collaboration and innovation among researchers, developers, and everyone. By sharing knowledge and resources, open source AI can accelerate progress and lead to breakthroughs that might not have been possible otherwise.
              * Accelerate progress. Breakthroughs that were previously impossible
              * Collaboration incentivizes everyone to do good for everyone else. Win win
            * Open source AI can potentially incorporate diverse perspectives and mitigate bias. No emo CEOs that hate jocks putting that hate into AI.

            * [x] Past events that prove benefits to safety due to open source tech that would not be possible if tech was closed source (thanks GPT)
              * GPT response
                * Certainly! Open source technology has also contributed positively to safety and security in many instances. Here are some examples where open source technology provided benefits that may not have been possible with closed source alternatives:
                  * Linux and FreeBSD: These open source operating systems have been praised for their stability, security, and performance. Many critical infrastructure systems, web servers, and even supercomputers rely on Linux or FreeBSD due to their strong security track record.
                  * OpenSSL security improvements: Following the Heartbleed vulnerability, the open source community rallied together to improve OpenSSL's code, security practices, and testing. This effort led to more robust cryptography libraries and practices that benefit the entire internet.
                  * Collaborative malware analysis: Open source tools like YARA and Cuckoo Sandbox have enabled researchers and security professionals to analyze and combat malware more effectively. These tools allow for better sharing of threat intelligence and rapid response to emerging threats.
                  * WireGuard: This open source VPN protocol has gained popularity for its strong security and ease of use. Its transparent and community-reviewed codebase has helped identify and fix potential vulnerabilities, resulting in a more secure VPN solution than many closed source alternatives.
                  * Let's Encrypt: This open source certificate authority provides free SSL/TLS certificates, making it easier and more affordable for websites to implement HTTPS encryption. As a result, web traffic has become more secure, protecting user data and privacy.
                  * Signal: The open source messaging app Signal uses end-to-end encryption to secure communication between users. Its transparent codebase allows security experts to review and verify its security claims, building trust in the app's privacy protections.
                  * TOR (The Onion Router): This open source software enables anonymous communication, protecting user privacy and promoting internet freedom. TOR's open development model allows for continuous improvement and has played a vital role in enhancing the safety and security of the network.
                * These examples show that open source technology can bring significant safety and security benefits by enabling collaboration, transparency, and rapid response to emerging threats. The open nature of these projects allows for continuous improvement and wider adoption of best practices, which may not always be possible with closed source alternatives.

        * random thoughts
          * Random people giving away open source work
            * Their work goes to both GOOD and BAD
            * Do they benefit from their work?
            * Is it more likely their work benefits others. Will GOOD beat BAD?
            * Will the fight of GOOD vs BAD kill everybody
      * Centralized AI route
        * Risks vs Benefits of centralized AI
          * Risks of centralized AI
            * 1) Any company with more advanced knowledge of AI systems can control society if only they control the knowledge and tools.
              * Good-intentioned company
                * They could think they are using AI for good, but actually ends up they are using it for bad.
                  * Example: the good-intentioned company stops progress of AI by keeping the tech to themselves. Little did they know, an evil company discovered the tech on their own and surpass every other company in terms of tech. They then start using AI for evil. The methods for counteracting this tech is non-existent because the good-intentioned company stopped AI progress by doing closed-source.
                    * Are there reasons that some evil company would not surpass every other company in AI tech?
                      * IP rights could halt them, but doubt it imo.
                    * The only hope for survival from evil company is that the good-intentioned company can catch up on their own by themself since they decided on closed-source
              * Bad-intentioned company
                * They could use AI for evil
                  * literally killing their enemies using AI.
                  * controlling various aspects of society using AI
                    * Forcing people to do things they dont want to do
                      * Automating people's jobs away and only giving them money to do terrible jobs that only benefit evil company

            * 2) Halting progress of technology and more and more people die to natural causes, crime, etc - just like always. New technology could have already solved cancer, aging, and more. But that is a "could", no one knows how fast technology actually would progress or if it could cure diseases and prevent crime more.
            * Corruption
              * Even if company is mostly good, there is the potential for bias and discrimination. If a centralized AI system is designed and controlled by a homogeneous group of people, it may reflect their biases and values, which could harm marginalized groups.

            * [x] Past events that prove risks to safety due to centralized tech that could have been prevented with open source tech
              * GPT response
                * Here are some past events involving centralized or proprietary technology that led to safety or security risks, where open source alternatives might have been able to mitigate or prevent these incidents. Open source technology often benefits from community-driven development, decentralized oversight, and increased transparency, which can lead to improved security and resilience.
                  * Stuxnet (2010): A computer worm that targeted industrial control systems, specifically those used in Iran's nuclear program. The proprietary nature of the targeted systems made it difficult for the wider community to identify and address vulnerabilities. Open source alternatives might have benefited from the expertise of a broader developer community.
                  * Adobe Flash vulnerabilities: Adobe Flash, a proprietary multimedia platform, was notorious for its numerous security vulnerabilities. An open source alternative with a transparent development process might have had fewer security issues or facilitated quicker fixes.
                  * Sony PlayStation Network breach (2011): A massive security breach affected millions of PlayStation Network users, compromising their personal data. An open source infrastructure might have benefited from better security practices and wider scrutiny from the developer community.
                  * SolarWinds cyberattack (2020): A supply chain attack on the proprietary network management software Orion led to numerous government and private sector organizations being compromised. Open source alternatives might have had more transparent development processes, allowing for better identification and patching of vulnerabilities.
                  * Microsoft Windows vulnerabilities: Over the years, the proprietary nature of Microsoft Windows has led to numerous vulnerabilities and cyberattacks, such as WannaCry and NotPetya. Open source operating systems, like Linux, often benefit from more transparent development and a larger community focused on identifying and addressing security issues.
                  * Zoom security concerns (2020): During the early days of the COVID-19 pandemic, the video conferencing platform Zoom faced various security and privacy issues. An open source alternative might have had more transparent development practices, allowing for quicker identification and resolution of security concerns.
                  * Apple's iOS vulnerabilities: Although Apple's iOS is generally considered secure, it has experienced several high-profile vulnerabilities, such as the Pegasus spyware. Open source mobile operating systems could benefit from community-driven security improvements and increased transparency in the development process.
                * While these examples highlight situations where open source technology might have offered some advantages over centralized or proprietary alternatives, it's important to note that open source is not inherently more secure. Both open source and closed source technologies have their own set of advantages and challenges when it comes to security and safety.
          * Benefits of centralized AI
            * The transition society goes through to new future will be less risky (MAYBE)
              * Transition events
                * Everyone's job gets automated and no-one can get job. No job = no money = no food, etc
                  * Person A is replaced. Their salary was $100k. Good-intentioned AI company that replaced job pays sub-company $50k and Person A $50K. Basically UBI somewhat and transition is easy. No harm happens. 
            * It's possible that keeping tech closed source will keep evil companies away from these powerful tools. At least keep evil away from the tech long enough that we can learn what to do if they do get hands on the tech.
              * Personally, i dont think so, but it's worth considering.
            * Centralized AI will most likely be more careful of risks when innovating.
              * They will probably spend more time on detecting risky scenarios and what to do if a risky scenario starts
                * Example: shut down servers if paperclip optimizer happens 
            * [x] Past events that prove benefits to safety due to centralized tech that would not be possible if tech was open source
              * GPT response
                * Centralized or proprietary technology can also offer safety benefits in certain situations. Here are some examples where centralized technology provided advantages that may not have been possible, or as effective, with open source alternatives:
                  * Apple's iOS security: Apple's centralized approach to its mobile operating system, iOS, has resulted in a secure environment with fewer malware incidents compared to open source alternatives like Android. Apple's strict control over the App Store and the iOS ecosystem has contributed to a more secure user experience.
                  * Microsoft's Patch Tuesdays: Microsoft's centralized management of Windows updates has allowed the company to systematically release security patches on a monthly basis (known as Patch Tuesday). This regular schedule helps users and IT professionals keep systems up-to-date and secure.
                  * Cisco's Talos Security Intelligence: Cisco's centralized approach to threat intelligence and security research allows the company to provide its customers with timely and actionable information on emerging threats. This information helps protect networks and devices from known vulnerabilities and exploits.
                  * Tesla's vehicle security: Tesla's centralized control over its vehicles' software has allowed the company to issue over-the-air security updates and patches. This approach enables Tesla to quickly respond to and address any security vulnerabilities that arise, providing better protection for its customers.
                  * Proprietary antivirus software: Many centralized antivirus solutions, such as Norton, McAfee, and Kaspersky, offer comprehensive protection against various threats, including malware, ransomware, and phishing attacks. The proprietary nature of these solutions allows companies to invest in research and development, providing users with up-to-date security features.
                  * Security certifications for closed source products: Some closed source software vendors invest in obtaining security certifications (e.g., Common Criteria, FIPS 140-2) for their products, which can provide additional assurances of security and compliance for customers in highly regulated industries.
                  * Closed source hardware: Proprietary hardware solutions, such as HSMs (Hardware Security Modules) and TPMs (Trusted Platform Modules), are designed to securely store and manage cryptographic keys, ensuring a high level of security in various applications.
                * While these examples demonstrate the benefits of centralized or proprietary technology in certain circumstances, it's essential to recognize that neither open source nor closed source is inherently more secure or safe. Each approach has its own set of advantages and challenges, and the best solution often depends on the specific context and requirements.

        * Arguments for centralized AI
          * Normal open source benefits people, AI open source benefits companies that can run it 
            * Anecdotes from me
              * GPU expensive bruh
          * The transition with centralized AI is much more SAFE than transition with open source AI
          * If small company or one person can use AI that can manufacture killer robots, that is not good lol. If only centralized companies have AI tools and are regulated to hell, then maybe less likely for anyone to manufacture killer robots?
            * this issue goes beyond software
        * thoughts
          *  Unknown if GOOD company or BAD company is ahead of the game. Unknown who is ahead.
            * If BAD company is ahead, then everyone dies most likely
            * If GOOD is ahead, then that's GOOD
              * But centralized control almost always corrupts, so have to be careful
          * Controlling IP
            * can be used to prevent bad actors from getting advanced technology. This slows down progress overall, which can be bad, but can be good if it prevents bad actors from killing us all.
      * Additional things to consider
        * open source may level the playing field between small companies and large companies:
          * worth considering the impact on small and medium-sized companies. While large tech companies may have the resources to invest in AI development regardless of the model, smaller companies may be more reliant on open source AI to compete. By promoting open source AI, we may be leveling the playing field and promoting greater innovation across the industry.
    * Try 2

