  * tracking learning how ethernet works
    * [[2024-10-24]] auto-negotiated network speed, what hardware considered in that speed, what are NICs n what they do, preamble relation to bit period #memo
      * Q: at the lowest level, do computers always use bits? or because modulation schemes can map multiple bits per symbol...does that mean the computer is no longer using bits?
        * NOTE: physical bit is different than digital bit (not physical)
        * Yes always uses DIGITAL bits. Always uses PHYSICAL bit in processing. In communications with NICs with symbols, physical bits are no longer used (but endpoint still digital bit)
        * **Processing:** All processing within the CPU/GPU occurs on physical bits (altho can have parallel processing of these bits)
        * key 4 me: the physical symbols are indeed physical and encode/embed more bits/data, BUT they are used between the NICs (communication/network systems)
        * the final end-point of data is ALWAYS represented using bits non-physical. BUT final end-point of physical data is not ALWAYS the physical bit (thanks to physical symbols - mapping physical to represented-state in bits - they no longer physical, as individuals at least)
        * when processing, physical bits are always used. when representing data - always uses bits (digital). when communicating using NICs, the physical states are often symbols containing multiple bits, but those physical states always get converted to digital bits - but NOT TO physical bits. AND much of this data never makes it to CPU after being received. Now if that data ends up used by app, then yea of course CPU will process - but lots of energy saved in network communication it seems
      * auto-negotiated network speed: When two Ethernet devices connect, they often undergo a process called **auto-negotiation**, where they agree on the fastest speed both can support - this resolves with final say on what speed is between 2 devices
        * what decides this auto-negotiated network speed standard:
        * **IEEE Ethernet Standards** that specify the speeds (like 10 Mbps, 100 Mbps, 1 Gbps, etc.).
          * so speeds are defined by standards groups and then applied to various hardware
          * the various hardware with defined speeds calculated in auto-negotiation to get final network speed used between 2 devices:
          * **Ethernet Cables** (which can have diff speed standard than its own connectors): The standards define which cables can support what speeds. For instance:
            * **Cat5e**: Up to 1 Gbps (Gigabit Ethernet).
            * **Cat6**: Up to 10 Gbps over shorter distances, commonly used for 1 Gbps or lower.
            * **Cat6a/Cat7**: Designed for up to 10 Gbps over longer distances than Cat6, with better shielding.
            * Newer cable categories like Cat8 are designed for even higher speeds over short distances, typically used in data centers.
            * random: just wanted to note it seems most ethernet cables use copper wires - they conductive boiii
          * **Network Interface Cards (NICs)**: The NICs in computers, servers, or other network-attached devices must comply with IEEE standards to operate at specified speeds. For example, a NIC might support 10/100/1000 Mbps (Fast Ethernet and Gigabit Ethernet) or even higher, like 10 Gbps, 25 Gbps, 40 Gbps, or 100 Gbps.
            * another name: WIFI adapter - which made me learn that wifi NICs and ethernet NICs are totally different - cant be used interchangeably...which makes sense bc my PC needs external wifi adapter/nic to use wifi
            * NOTE: in phones, iz not using NICs, but using other thingz
              * The **baseband processor** is NIC for cellular data and voice. It handles signal processing. A broader term containing the BP is the Cellular Modem - The modem performs both digital processing (handled by the baseband processor) and the actual radio transmission and reception (done by the radio transceivers)
              * AHH: BP handles digital signal processing and transceiver handles ANALOG signal processing. And phones do literally have antennas lol. Each module can have diff transceivers too, just depends. Tbh can think of SoC as a very abstracted NIC
              * The **Wi-Fi module** is NIC for internet access through local wireless networks.
              * The **Bluetooth module** is NIC for short-range device-to-device communication.
              * all these components are often integrated into a **System on a Chip (SoC)** in modern smartphones, where a single chip (like Qualcomm’s Snapdragon or Apple’s A-series) handles all these functions
            * these are hardware in computers that actually connect to the network - they receive/send the voltages between each device
            * they do outputting of voltages representing bits/symbols and receiving of these voltages. in ethernet there's some less memo-y stuff before NIC, but dont really need to know
            * whereas with wifi, it's somewhat important to realize that data has to be caught by **antenna** that acts as the first receiver for radio frequency (RF) signals, converting these signals into electrical signals. THEN, turns data from WIFI frames to ethernet frames inside MAC layer of NIC - and from then on same process as ethernet
          * **Switches and Routers**: These devices must be capable of handling the speeds defined by the IEEE standards. A switch or router might have ports rated for different speeds (e.g., 1 Gbps, 10 Gbps, etc.)
          * **Connectors and Ports**: The physical connectors - which are the ends of ethernet cables (like RJ-45 for traditional Ethernet) and the ports they plug into must also match the speed capabilities (this emphasizes ports of computer, since ports of routers/switches already discussed)
          * **fiber optic cables too have standards**..they maybe have their own auto-negotiation process - idk tho
          * other factors are included in auto-negotiation, but not supah important to know: **Duplex Mode**: Whether the connection will operate in half-duplex or full-duplex. Full-duplex allows communication in both directions simultaneously, which is preferred for higher performance., etc
        * FINALLY, this final network speed actually defines the BIT PERIOD which tells you time interval to transmit one single bit. It is the reciprocal of the transmission **bit rate**. 100Mbps (bit rate) -> 1/100million = 10ns (bit period)
      * ethernet sends data bit by bit (well...used to), while wifi sends data symbol by symbol (each symbol containing x bits)
        * this bit rate and bit period is important for ethernet bc that's how it looks for representations of 0s/1s by changes in voltage
        * many encoding types like Manchester Encoding represents 0 with change from -xvolts to +xvolts and vice versa - but it must happen within the defined bit period from negotiated network speed
        * i imagine vertical lines (but measuring horizontally) like on meter stick defining bit period and within each is sine-wave transitioned from - to + or vice versa
        * ethernet data is sent as ethernet frames. at first no signal is sent. then a PREAMBLE is sent. it is just repeating 010101.. - this and the bit period in general allows the 2 devices to sync their clocks. if voltage changes seem to be drifting - so not quite happening within the bit period, then gotta resync, Preamble bits are same bit period with test data...to test and sync if needed
        * cant remember if i noted elsewhere, but wifi signals have a preamble with same purpose of syncing too
        * every ethernet frame has preamble just in case need to resync. After preamble in frame is the actual data yay
        * a symbol is basically: a resolved value from (list of physical/voltage states) and (list of represented digital-bit states) defined by predefined model (encapsulates these lists and their mappings). So depending on context (am i looking at symbol as physical state or represented state), depends what symbol will be. Could be a voltage or a representation like 10. BUT you can get one from the other bc they mapped. ^pxcrv9fmn
        * PHYSICAL OBJECTS THAT REQUIRE PROCESSING: label for these physical circuits that arent just voltage states: signal processors. Digital-to-Analog Converter (DACs), ADCs (Analog-to-Digital Converters) - often other types of circuits too. They input/output just voltage state tho onto transistor (dont have to break down to old physical states of 1s and 0s...for netty comms at least)
        * physical states of just voltages used to represent just 0 or 1. Now physical states map to symbols - but they complex physical states which Requires hardware (ADCs/DACs) to be aware of what symbols are - and know and do mapping model from physical-state to represented-bit-state (predefined models). i think a symbol is this mapping pair - so it's both in reality, but also term symbol can be used for just one side (and know it's mapped to the other side as defined by model)
        * 0 and 1 still 2 of the represented states, but there's other represented states now too (ex:01,10) in better modulation scheme. More physical states give more represented states. And a new model (mapping physical-states to represented-states) physically built into ADCs/DACs allow/enact this onto transistors. intelligence is relative and iz process of going from one model to other that is better. Better bc does same action in less time and less energy - communicates data in less time and less energy. NOTE: better in terms of intelligence, but not other things like creativity or fulfillment…altho more intelligence can often lead to that
          * lol: i was unconsciously converting these to base-10 which caused confusion. 00 and 0 are not same. maybe in base-10 they can be same, but one is one-bit and other is 2 bits (and digital bits are always what's used for representation of data/represented-states). Still feel this is insightful tho
        * interesting: signal interpretation/processing seems to be where most improvement comes from in BCI and in computers (at least for network comms) - and in our human brains probably! maybe one day we will be able to find the smallest force/work a human can control consciously and then map from there. BUT i imagine you can make infinite models to map to the minimal physical states/force/work
      * memo updates
        * [[2024-11-20]]
          * i kinda forgot names 4 phone version of NICs woops
        * [[2024-12-20]]
          * remembered SoC, cellular modem...but not name of baseband processor (iz da base of net coms 4 cell) woops or diff in that and cellular modem

    * [[2024-10-29]] basically understanding data compression/encoding and hardware and physics of it - just memo using what's inside #memo
      * Q: what changes PHYSICALLY between ethernet 1:1 bit modulation/encoding/decoding vs 1symbol:many-bits? does the physical hardware need to understand some sort of predefined model to encode/decode from symbol:many-bits? 
        * PREFEDINED MODELS: what changes: different predefined model used by ADCs/DACs and other associated NIC circuits (when hardware is BUILT, it is physically defined what list of modulation methods/models can be used). The physical changes at small levels are complex, but often totally different circuits and whatnot between each method/item in list of models/modulation methods (altho one NIC CAN support multiple predefined models btw)
        * WHAT A MODEL: you can think of each model as defined here: [[ShmojiMindMapPublic-2025-05-24-12-15-07_cleaned/ShmojiMindMapPublic-2025-05-24-12-15-07_cleaned/ethernet#^pxcrv9fmn|a symbol is basically: a resolved value from (list of physical/voltage states) and (list of represented digital-bit states) defined by predefined model (encapsulates these lists and their mappings). So depending on context (am i looking at symbol as physical state or represented state), depends what symbol will be. Could be a voltage or a representation like 10. BUT you can get one from the other bc they mapped.]]
      * BAD Q so skim: "To handle multi-bit symbols, the hardware needs ADCs and DACs with finer granularity and higher sampling rates."

requires higher sampling rates kinda confuses me. i imagine only one sample happens per symbol which then gives you multiple bits. whereas before you had to do 1 sample per bit. is this wrong thinking or no?
        * BAD QandA: tbh this is just not clear QandA. depends on context and what kinda sampling you talking about. We can just say: GPT was wrong i guess. im correct iz 1 sample per symbol. But good 4 learning.
        * MORE PRECISE SAMPLING 4 MORE COMPLEX symbol:bits MODELS: BUT 4 sure need more **precise sampling** (higher resolution ADCs/DACs) to do conversion of physical/voltage-state to represented state (gotta go through list of mapping pairs) - which this conversion and list are much more complex as you pack more bits into a symbol.
        * PARTIAL RESPONSE ENCODING RELATION: this reminds me of partial response encoding (which requires coupled ethernet wires for higher resolution that increases throughput), except it's symbol-to-bit encoding needing higher resolution (bc instead of simple 0 and 1 voltage states, ur dealing with more states and more complex model for differentiating them)
        * THROUGHPUT INCREASE METHOD 4 EACH: Seems like throughput increased with symbol-to-bit encoding by using DESIGN enacted onto physical so they use pre-defined models. Whereas, partial response encoding increases throughput by squishing signals together and removing noise (requires design still, but less focused on design/models and more focused on physics/reducing-noise/increasing-signal-through-hardware).
      * MORE EFFICIENT bc MORE SMART/COMPLICATED MODEL: removing work/energy-used/literal-physical-objects thanks to physical systems built in beginning with smarter/more-complicated mapping models:
        * see if you can find error in next note. it's only partially wrong
        * in past: +1v = 1 and -1v = 0

NOW: +1.1V=11, -1.1V=00, +.43V=10, -.43V=01

so a specific voltage still represents 0 and a specific other voltage still represents 1 (but in 2 bit format)

so that 1 voltage state of +1.1V is now doing the physical job that 2 old physical states used to do bc 2 bits (less physical states needed). This can happen bc hardware has predefined knowledge/model. it knows that +1.1V=11 (2 bits). BUT 00 and 01 are still one-shot in same amount of time as old model using 0 and 1
          * EDIT: this is wrong, i was stuck in base-10 mode without realizing. all new states double data
          * DOUBLES DATA CAPACITY of a SYMBOL and up: it effectively doubles the data CAPACITY by switching to quaternary (four states for 2 bits) rather than remaining binary (two states for 1 bit). NOTE: ternary not used in these models but iz 3
          * BLACK VS WHITE BIAS: learnt that getting rid of more 0s and have more 1s would not increase data rate. Not even sure why i had this intuition. black vs white bias? balance be more important for signal?
          * AHA: Statistical Encoding: Techniques like run-length encoding or Huffman coding increase efficiency by taking advantage of patterns within the data (e.g., long runs of 00s - or any pattern really)
            * PATTERNS IN INPUT OF APPS: so it's based on the data being used. i imagine an app may be giving data however it wants to the hardware. There may be repetitive patterns in there that can be found statistically! then these encoding methods can make their own type of symbols (yes physical) based on these patterns! coooool
            * this happens at hardware level in NICs and can make symbols encode even more data by exploiting these found patterns.
        * TRANSISTOR AND SAMPLING/TIME IMPROVEMENT: Each state is stored on a transistor. But transistor doesnt even know what it is representing. BUT in one instant, a single physical state of NEWER MODULATION (1 transistor representing 11) can tell you what took 2 physical states in 1:1 modulation (2 transistors) and took 2 samples/cycles
        * SAMPLES vs CYCLES: i feel samples is mainly about decoding at end and computation time of that (in an instant). Whereas CYCLES is ALL OF IT - encoding/decoding, time to send symbol - it's the mapped-time-interval OR the symbol-period in ns...usually
        * TYING QUATERNARY vs BINARY TO PHYSICAL: there's more literal physical states/symbols in the model...well what is actualized depends on context, no point in entire model actualized at once lol (+1.1V, -1.1V, +.43V, -.43V). similarly, there's more represented states DIRECTLY mapped to these physical states (11,00,10,01). Previously was just 2 (0 and 1)
        * BAD Q again skim: say you have modulation scheme1 that 1 symbol = 1 bit. then you have modulation scheme2 that 1 symbol = 2 bits. would 0 represented in both schemes be transmitted by ethernet in same time? what about one of the new states in new scheme not present on old scheme, like 11?
          * VOLUME NOB SYMBOL SENDER/SIGNAL: since the voltage output of NICs are more gradual now, there is no hard changes - so the symbol rate ends up being most accurate timing for voltage output to voltage output...but again it's gradual...there are no hard voltage output changes - iz like volume nob sender and receiver
          * OFTEN FREQ AND AMPLITUDE USED: depends on encoding method, but often frequency changes AND voltage changes important and sampled
          * 1ST LEARNING ABOUT COMPOSITE SINEWAVES: there's often multiple different sine-waves (with differing frequencies and amplitude) sent at ONCE per symbol. These sine-waves combine into 1 sine-wave, but then can be re-separated. the frequency bandwidth like 100MHz is a range from 0-100MHz - each child sine-wave used can be anywhere in that range (same for composite sinewave). Combining all this info together you can decode 1 symbol...yeesh complicated
          * ### Example
            * JUST EX: if a symbol period lasts for 8 ns, during this time, the voltage level could gradually transition from one amplitude to another as part of the modulation scheme. For instance:
              * EX OF WHAT SIGNAL INSIDE SYMBOL PERIOD CAN LOOK LIKE: it might start at a lower voltage, peak at a higher voltage, and then drop back down to signify the end of the symbol.
              * Different parts of the symbol period could exhibit varying amplitudes due to the underlying multiple sine waves.
            * CALC MAY BE WAY MORE COMPLEX THAN JUST DEM AMPLITUDES: after all info is CALCULATED, you get the end voltage-state - but this voltage state doesnt have to be present in amplitudes of a symbol period (of solo sine-waves or composite one)
            * CAN SEND MULTIPLE FREQs AT ONCE: thinking about frequency bandwidth of an ethernet cable. like 100MHz for gigabit. This 100MHz is a range from 0. one output can have multiple sine-waves frequencies sent at same time as composite sine-wave - ex: 10MHz, 5Mhz, 50MHz all at same time
            * WOAH: i learned there can be HUNDREDS of additive sine-waves that get combined into the one composite sine-wave...thaz alot
            * all dis stuff related to **Fourier Series/Transform** but i no learn that now
            * **Multiple Sine Waves AT ONCE IS EX OF MULTIPLEXING**: In the context of transmitting data over Ethernet cables, multiple sine waves are indeed sent simultaneously. This is part of a technique known as **multiplexing**. **Multiplexing** is a technique used in communication systems to combine multiple signals into one signal over a SHARED medium. The goal is to make efficient use of available bandwidth by allowing multiple data streams to share the same transmission medium without interference. i THINK this is only multiplexing bc multiple symbols transmitted in parallel due to multiple wire-pairs, each carry 1 symbol at same time (altho GPT disagrees and says they all part of same signal so not multiplexing). same-signal multiplexing vs differing-signals multiplexing/datastream
            * Q: if bandwidth is used, does that mean multiplexing is being used?
              * me: yes. most LLMs: no. all about definitions tho
              * MY DEF OF DATASTREAM: i consider datastream to be unique flow of data EVEN if same SIGNAL (maybe 2 types - one independently decodable and one not - like child sine-waves tied to parent). Maybe i should call it a data pathway...or river...or sometin. GPT does not consider child to be unique datastream if the child datastream is same signal/data as other childs/parent. BUT i do - iz unique flow of data - and there's 2 types i mentioned
              * MAYBE: maybe i can replace GPTs word for datastream with signalstream
              * JUST ANOTHER EX TO CONTRAST DISAGREEMENT: **Composite Signal**: A single data stream modulated onto a carrier wave. The multiple frequencies within the composite signal represent the components of that one data stream (e.g., audio frequencies for sound, video frequencies for images), but they aren't separate, independently decodable signals. me: i consider each frequency a unique datastream, but GPT doesnt bc all the childs/parent are same signal/data
              * like i said earlier: same-signal multiplexing/datastream vs differing-signals multiplexing
              * GPT REASONING FOR WHY **Ethernet Not Traditional Multiplexing**: The term **multiplexing** typically refers to combining **multiple independent data streams** (e.g., different phone calls or TV channels) into one signal for transmission over a shared medium. Ethernet's use of multiple wire pairs does not fall into this category because each wire pair isn't carrying an independent data stream that is later separated; instead, they're all working together to transmit parts of the **same data stream** in parallel. me: imo they are unique datastreams, but not unique signalstreams
              * meme: my definitions have high resolution tehe. They focused on unique signals, im focused on unique data
          * ### Example Analogy
            * INSTRUMENTS IN A BAND: imagine each sine wave as a different instrument in a band playing a different note. Individually, each instrument has a distinct pitch (frequency) and volume (amplitude). When they all play together, you hear the harmony and interference between notes, which gives a rich, complex sound that wouldn’t exist if any of the notes were played alone. The complex waveform is like the resulting "sound" of all frequencies combining into a shared signal across the Ethernet cable. me: Each instrument is a datastream and you can have each instrument play alone too (altho with a symbol that doesnt make sense bc the partial data only makes sense as a symbol)
          * THROUGHPUT: **throughput is the effective data rate** achieved, reflecting the actual capacity of the channel to carry useful information over time
            * HOW MUCH DATA WE BE GETTIN IN x TIME-PERIOD INCLUDING PARALLEL: Throughput is the amount of data successfully transmitted over a network (or processed by a system) in a given period of time. It’s often measured in bits per second (bps), like megabits per second (Mbps) or gigabits per second (Gbps), and is a practical indicator of how much data the system can handle in real time (a rate, i/o)
            * EX OF INCREASING DATA/throughput WITHOUT CHANGING SPEED: For example, with a multi-level/bit modulation scheme, more bits are packed into each transmitted symbol, which means that even if the symbol transmission time remains the same, the **throughput increases** because more data (bits) are carried in each symbol.
            * Q: how is this different than bandwidth?
              * tbh they often used interchangeable. BUT throughput is real world rate factoring in interference and everything else. bandwidth is theoretical MAX data-rate (and also a range of frequencies that can be used)
              * so, take max freq of bandwidth (100MHz from 100MHz, not 20MHz) and that is theoretical MAX data-rate. in reality, maybe you have microwave in way of router/satellite, so throughput is REAL rate like that
              * in rare cases like partial response encoding, T can be greater than bandwidth bc squishing symbols together
            * UNITS: typically see both B and T as Hz in frequency bandwidth (RF) and as bps for digital bandwidth like ethernet (but both units can be interchangeable)
            * connecting to something tangential: **throughput-Oriented**: While CPUs are latency-optimized (quick at handling single tasks round trip with low delay), GPUs are throughput-optimized, meaning they excel at processing massive amounts of data in parallel. No idea if this will stay true into the future. Seems CPUs good for sequential logic and GPUs good for parallel stuff and math. So maybe throughput can sometimes sacrifice a specific task for the whole due to doing things in parallel?? i dont think thaz always true tho
          * CONTRAST OF PHYSICAL/ENERGY CHANGES BETWEEN BETTER MODULATION METHODS: time per bit is no longer a physical thing really. may be useful for us humans, but not really physical thing in newer modulation. because samples are taken per symbol and symbol directly maps 1:1 to physical state. i guess time per bit can be useful just to compare improvements tho and bc digitalbit is endpoint. but now what's physical is time per symbol. if you kept time per symbol same as previous time per bit (so time per sample is same), you'd keep same energy usage, but represent a lottt more data more quickly. if you kept same old bit rate despite using symbol modulation (and made new bitrate HAVE same old bit rate but symbol rate is different), time per sample/symbol would be much LONGER time period (less samples), yet represent SAME amount of data. 1 sample = takes less time/energy = same data tho
          * PHYSICAL STATE ON TRANSIST IN INSTANT vs CYCLE/TIME-PERIOD/DBITS: interesting observation: a physical state is an instant, but the sample/cycle is a time-period that basically gets mapped to that physical state (imagine sine-wave between 2 vertical bars - iz 1 physical state represented over time). Never see people differentiate these, but feel that's important. i think the sample/cycle + data encoded in it basically is the represented-state/digital-bits. Seems physical states are more physical in an instant + energy. Represented-states/digital-bits are physical too, but are more defined by time (rather than energy). It's like represented-states/dbits/cycles are the time-equivalent of the physical states or you could say the physical states contain those time-dense represented-states. Both are enacted onto transistors by ADCs/DACs
          * important: one transistor at one point could be +1.1V representing 11, but then later be +0.43V representing 10
      * ALL MODELS CAN REPRESENT ALL THINGS: each model is kinda like a language. better model dont rely on previous models (but they all do convert to endpoint of the digital-bit, all represented states are 1+ dbits hooked to physicalstates/symbols), theyre completely new - but both models can still represent the same "things/data/info" despite different physical states and different represented states (thanks to digital-bit endpoint maybe?). interesting: you can represent all represented-states in worse or better model. worse just takes more samples/cycles/time
      * Q: how does energy used change as throughput changes?
        * HIGHER RADIANT ENERGY, LESS ENERGY PER UNIT DATA: high throughput generally means higher total/radiant energy consumption (imaging ppl who got better hardware getting more FPS), but the energy spent per unit of data transferred (energy per bit) often decreases, making the transmission more energy-efficient.
        * so efficiency is about usage per unit
        * actually higher total energy transmission isnt true. that is based on an assumption that with higher throughput comes increased demand/increased data, but that's not always true. i could see this being case with video games and getting better hardware. but for async processes - no not really. definitely an assumption there
        * **Jevons Paradox** (i heard from Lex poddy): When the efficiency of using a RESOURCE improves (for example, through technological advancements), the effective cost/price of using that resource decreases. This decrease in cost often leads to increased demand because the resource becomes more accessible or cheaper to use in larger quantities. meme: jevons sounds like particle lol
      * memo updates
        * [[2024-11-08]]
          * main thing that slipped my mind was multiplexing. think i have better definition and distinction for it and datastreams now
        * [[2024-11-23]]
          * this is way too much info but idk what to delete or what to do about it. EDIT: i came back and edited, hopefully good now
          * these notes make me ponder on: it's cool that you can represent anything with any model. every possible representation is possible with any model used: binary, quaternary, etc. But idk if this is actually true in the non-computer realm. And then i start wishing i still understood turing machines, what they are, turing complete, and the halting problem. EDIT: ahh yea maybe you can represent anything with any model, but cant compute anything with any model - computation brings in limits
        * [[2024-12-20]]
          * this still feels like too much info
          * struggled to remember multiplexing again. struggled with differentiating throughput vs bandwidth a lil. it all came back quick tho for all of it.

    * [[2024-10-31]] understanding differential signaling and partial response encoding #memo
      * memes: channel, band, bandwidth, pulse shaping
      * MULTI CARRIER WAVES vs 1 CARRIER WAVE: you can think of each subcarrier in RF systems as a different base/carrier wave with data modulated on it and gets added with band carrier to composite single wave. Whereas ethernet is one carrier wave 4 sure with many other non-carrier waves added to it. so multiple carrier waves vs 1 carrier wave. both do indeed have many solo-non-carrier-waves added to the carrier wave
        * NOTE: i dont think dis 2 important, so feel free to skim lol
        * SIMILARITY OF RF SUBCARRIERS AND ETHERNET WIRE PAIRS: i think you can somewhat relate RF subcarriers to ethernet wire PAIRS. Each subcarrier sends one symbol in parallel with other subcarriers. Same with each ethernet wire pair (plus some additional tricks). Difference is that subcarrier's is added to a more parent-level carrier wave, but ethernet doesnt do dat - just one carrier-wave per symbol/wire-pair
        * RF system do this (have multiple carrier-waves) to prevent interference in high traffic datastreams. Whereas wires no need to worry - they dont share communication medium
        * note: iz interesting bc in ethernet, time to communicate one symbol in one wire is mainly decided by bandwidth of channel (plus few other things). in RF system, iz decided by (subcarrier-spacing * numSubcarriers) bc combining all spacings can differentiate each subcarrier wave (carrying 1 symbol) all at once (instead of being decided by some chosen max bandwidth/frequency like 100MHz, the spacing between diff bandwidths give you the info). for ex using LTE:
        * neat: subcarrier spacing is basically single subcarrier bandwidth and you just gotta add dem all up. you really dont know what frequency is used for a subcarrier or a carrier (even for ethernet), but you can use ethernet bandwidth as max theoretical frequency and thuz symbol rate (time to transmit a symbol yay). But RF iz different in that it has multiple subcarriers, hence multiple bandwidths separated by that particular bandwidth spacing so can differentiate data inside each subcarrier. (depends on modulation scheme, but often each subcarrier carries 1 symbol)
        * each LTE subcarrier spaced at **15 kHz**, the **symbol duration** is about: 1/15000 = 66.67microsecs
        * Each subcarrier transmits one symbol every 66.67 μs, so the **symbol rate per subcarrier** is: 1/66.67microsecs = 15k symbols/s (reciprocal of symbol duration gives symbol rate...but spacing already told us that lol so dis not needed unless just wanted to know symbol period)
        * a **20 MHz LTE channel** consists of 1200 subcarriers, each spaced at 15 kHz: Total bandwidth=1200×15 kHz=18 MHz or 18M symbols/s
        * so in both ethernet and RF, total bandwidth and symbol rate are about same
      * NOTE: sometimes "channel" means like a path for something like data to flow (independent from other channels, so it unique or changes differently) - think a better term for this is datastream tho. Seems most of the time channel basically means specific range in spectrum (like 7kHz-10kHz). And membuh, often hundreds of unique sine-waves/signals with diff frequencies (limited by or contained in this range/spectrum) can be can be combined into one composite sine-wave/signal (Fouriererererer)
        * Q: does bandwidth mean same thing as range of frequencies?
          * **In Communications and Signal Processing**:
            * range of frequencies within a given signal or channel. For example, if a signal occupies frequencies from 20 MHz to 30 MHz, its bandwidth is 10 MHz.
            * Here, bandwidth is the *width of the frequency range* that contains most or all of the signal's power or information.
          * **In Networking**:
            * *Bandwidth* is often used to describe the *data transfer rate*, i.e., the MAX rate of data transmission over a network or internet connection (throughput is actualized version and not max), measured in bits per second (bps). Though frequency range is still relevant (since a higher frequency range can support higher data rates), bandwidth here usually implies the amount of data that can be transmitted per unit of time, not strictly the range of frequencies.
            * me: i still dont totally understand this. maybe it was just historically defined badly. maybe bc other def provides a max theoretical time for change/data-communication (probably)
          * Q: okay, so what is a band?
            * PARENT VERSION OF CHANNEL: it is a specific range of frequencies within the electromagnetic spectrum that has been designated for a particular purpose or type of signal (band and channel are basically same thing, but usually channels are child-nodes while bands are more parent-nodes)
            * If we take the FM radio band from 88 MHz to 108 MHz as an example, the *band* is this specific 20 MHz frequency span. Individual stations occupy smaller *channels* within this band, each of which has a specific bandwidth (so radio stations dont take just one frequency - they take a channel...which is also frequency range, but different than band)
            * Q to clarify: **Is 88.5 FM just at that frequency?**
              * No, 88.5 FM doesn’t occupy *just* 88.5 MHz; it uses a *range* of frequencies around that central frequency. This range is necessary because real-world signals (like music and speech) are more complex than a pure tone—they contain multiple frequencies and need "room" to transmit the full signal clearly. (1 composite sine-wave containing many other sine-waves with differing frequencies...kinda like different perspective or data of that one composite signal)
              * EX OF CHANNEL BANDWIDTH: For **FM radio** in the U.S., each station typically occupies a **200 kHz bandwidth**. So, 88.5 FM actually spans from roughly **88.4 MHz to 88.6 MHz**. This range is what allows FM stations to transmit a richer, high-quality audio signal (many sine-waves with differing frequencies and diff data modulated into each). In AM radio, stations also occupy a bandwidth (usually about 10 kHz in the U.S.), but their central frequencies are spaced out by at least 10 kHz to avoid overlap (not as much spacing for diff frequencies and AM more likely to have noise due to it being energy modulations instead of time/frequency)
            * so a channel can have a bandwidth and a band can have a bandwidth lol. make sense like i said above, theyre about same thing
          * Q: this is a frequency so it's telling how many of SOMETHING per second. What is that SOMETHING?
            * cycles/samples per second. cycle is one oscillation/repetition - 0 to peak to 0 to trough to 0 (ehh not always tho) - i imagine signal between 2 vertical bars. Can encode data/change/info in a cycle with slight changes due to confidence in repetitiveness. Gets complex once you have range of frequencies...now you dont really have one cycle...bc each frequency in the range IN ONE MOMENT/signal has it's own unique cycle time (BUT actually it iz still 1 signal bc all those sub-cycles are additive to make 1 composite cycle)
              * **Example**: If you play a chord on a piano, each note has its own frequency. When they’re played together, your ear receives all these frequencies simultaneously. They superimpose to create a SOUND that your brain interprets as a harmonious chord rather than separate, disjointed frequencies.
            * Q: i understand it's cycles per second - but doesnt a wave have 2 axis for cycles? couldnt the amplitude cycle at separate frequency than the time axis? or am i wrong about something here?
              * i am wrong. Amplitude doesnt oscillate like time axis does. the amplitude itself does not oscillate independently at a different frequency in a standard wave. It does vary in magnitude within each cycle tho - BUT it is tied to TIME domain to determine repetitive cycles, too bad so sad
          * VCR was ANALOG and TYLER: VCR could catch analog signals bc it had analog tuner that catches them - so Tyler used this to get analog cable TV back in the day WOAH. they had no bits on them. The actual audio content—the voice, music, etc.—is added onto this carrier frequency (like 101.1 MHz) using techniques like amplitude modulation (AM) or frequency modulation (FM) - but the content was not bits - the waves/voltage-changes represented real things like color, brightness, audio properties, etc. It makes sense VCR could catch signals bc i remember ppl using VCR to record shows lol - but also it feels weird bc i feel there should be BIG antenna to be catching this stuff but NOPE
      * WIRE PAIRS INCREASE THROUGHPUT WITH DIFF SIGNALING: it's not a FREQUENCY CHANNEL, BUT you can think of each PAIR of ethernet wires as a "channel"/datastream bc just adding one wire to the other one and using differential signaling (pos and neg of signal/symbol) increases throughput (like by 0.25 with Gigabit ethernet pairs using PAM-5 modulation). The whole is greater than the solo. The whole only increases by a lil bit, doesnt double signal (symbol rate), but doubling signal not even possible, so any increase is fire
      * just interesting: thinking about physical (closer to energy, heart) vs analog (on top physical, closer to math/mechanical, intuition, pattern-matching) vs digital (on top physical, closer to ???,logic,reasoning, rationalizing)
      * Q: why is it that if you have one ethernet wire, frequency range and symbol rate are the same. but if you have a pair of ethernet wires, the symbol rate increases a little bit? for example: in gigabit ethernet - the frequency range would be 100MHz and symbol rate would be 125Mbaud
        * partial response encoding: a symbol/signal/voltage is still only sent 100M times per second at max. it is due to partial response encoding. Basically, symbols (the encoded/modulated data) can overlap in the signal. With this overlap, you are squishing more of the data/symbols together - ex: 0.25 more symbols sent in one signal/voltage output (across 2 wires or one pair)
        * my confusion on frequency not increasing, but somehow symbol/baud rate increasing with adding wire pairs: so with one wire, you can get baudrate of 100Mbaud. i assumed with 2 wires you could get 200Mbaud. But then it seemed like 1 pair worked together just to do 100Mbaud. okay, so i thought that 2 pairs would be 200Mbaud. But then that didnt seem the case either. why?
          * WHY DIFF SIGNALING IS OP: you cant just add adjacent wire to do same baudrate as other wire due to electromagnetic interference (EMI) and other physical problems. BUT you can add a pair of wires that use differential signaling (pos and neg of same signal/symbol at same time) to slightly increase throughput (like by .25)
          * 2 PAIRS: so with 2 pairs you would indeed double baudrate. 125Mbaud * 2 = 250Mbaud. LLM had some confusion here 
          * Q: is pulse shaping and partial response encoding the same thing?
            * No. and dont worry too much about this, but use PRE term more
            * GPT summary:
              * **Pulse shaping** aims to smooth out signal transitions to control bandwidth and reduce interference (all about reducing interference...which prob doesnt increase data-rate necessarily). does not optimize how frequencies are used in the range. iz analog process for preventing interference
              * **Partial response encoding** deliberately introduces inter-symbol interference (ISI) to achieve higher data rates or other benefits, typically through controlled interdependencies between symbols (i think of coupled and differential signaling wires increasing data rate due to higher resolution data/signals) and squishhh
          * Q: is partial response encoding a different type of encoding than the type that maps symbols to multiple bits? are they using different hardware?
            * YES. They are very related and often both implemented at same time - even use very similar hardware. But they are different.
            * GPT summary
              * **Partial Response Encoding**: Focuses on the timing and shaping of the signals to increase symbol rate. a digital preprocessing step. and requires coupled wires using diff signaling discussed
              * **Symbol-to-Bit Mapping (e.g., PAM-5)**: Focuses on how many bits can be represented by each symbol.
          * X post: avenues of better signal processing:
            * fighting physics with hardware and understanding of physics/math(of waves lol) - Partial Response Encoding + Differential Signaling + coupled ethernet wires 
            * designing intelligent models that hardware is built on - symbol-to-bit mapping/encoding
              * separate from these models, but subset to this: designing the Fourier stuff with sinewaves to be max efficient - increasing data
            * building intelligent software that finds patterns and uses that to enact changes in hardware - Statistical Encoding: Techniques like run-length encoding or Huffman coding increase efficiency by taking advantage of patterns within the data. shiz will create its own symbols based on data patterns

